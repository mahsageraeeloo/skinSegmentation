{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in data set description was mentioned there is no missing data \n",
    "#?????????????????????check if you need to check if all the values are positive integers\n",
    "# df_samples.loc[~df_samples['B'].astype(str).str.isdigit(), 'CAT'].tolist()\n",
    "# df_samples.all(  isinstance(x for x in df_samples, numbers.Integral) )\n",
    "# all(x.is_integer() for x in df_samples.v)\n",
    "# df_samples.loc[~(df_samples['B'] >= 0) && , 'CAT'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #############################################plot to show that numbers of samples of categories are the same\n",
    "# target_count2 = df_samples['CAT'].value_counts()\n",
    "# type(target_count2)\n",
    "# target_count2[0] = y_train_res[y_train_res == 1].shape\n",
    "# target_count.plot(kind='bar', title='Count (target)')\n",
    "# y_train_res.shape\n",
    "# type (X_train_res)\n",
    "# type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# X = np.array(X_train_res)\n",
    "# y = np.array(y_train_res)\n",
    "# kf = KFold(n_splits=5)\n",
    "# kf.get_n_splits(X)\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     model = RandomForestClassifier(n_estimators=10)\n",
    "#     model.fit(X[train_index], y[train_index])\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_train_res, y_train_res, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# clf = RandomForestClassifier(random_state = 84)\n",
    "# param_grid = {\"n_estimators\": np.arange(2, 6, 2),\n",
    "#               \"max_depth\": np.arange(2, 4, 1),\n",
    "#               \"min_samples_split\": np.arange(2,4,1),\n",
    "#               \"min_samples_leaf\": np.arange(1,3,1),\n",
    "# #               \"max_leaf_nodes\": np.arange(2,3,1),\n",
    "#               \"max_features\": np.arange(1,3,1),\n",
    "#               \"bootstrap\" :[True, False]\n",
    "#              }\n",
    "\n",
    "# param_grid = {\"n_estimators\": np.arange(10, 1000, 10),\n",
    "#               \"max_depth\": np.arange(10, 200, 10),\n",
    "#               \"min_samples_split\": np.arange(2, 50, 1),\n",
    "#               \"min_samples_leaf\": np.arange(1, 50, 1),\n",
    "#               \"max_features\": np.arange(1,3,1),\n",
    "#               \"bootstrap\" : [True, False]\n",
    "#              }\n",
    "\n",
    "# def evaluate_param(parameter, num_range, index):\n",
    "# grid_search = GridSearchCV(clf, param_grid = param_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "# grid_search.fit(x_train, y_train)\n",
    "\n",
    "# mp.pyplot.figure(figsize=(16,12))\n",
    "\n",
    "\n",
    "# df_cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "\n",
    "# df_cv_results.columns\n",
    "\n",
    "# df_cv_results2 = pd.DataFrame(grid_search.cv_results_)[['param_max_depth', 'mean_test_score']]\n",
    "# df_cv_results2 = df_cv_results2.sort_values(by = 'param_max_depth')\n",
    "# mp.pyplot.subplot(3,2,2)\n",
    "# plot2 = mp.pyplot.plot(df_cv_results2['param_max_depth'], df_cv_results2['mean_test_score']) \n",
    "# mp.pyplot.title('param_max_depth')\n",
    "\n",
    "# df_cv_results2 = pd.DataFrame(grid_search.cv_results_)[['param_n_estimators', 'mean_test_score']]\n",
    "# df_cv_results2 = df_cv_results2.sort_values(by = 'param_n_estimators')\n",
    "# mp.pyplot.subplot(3,2,1)\n",
    "# plot = mp.pyplot.plot(df_cv_results2['param_n_estimators'], df_cv_results2['mean_test_score'])\n",
    "# mp.pyplot.title('param_n_estimators')\n",
    "# \n",
    "\n",
    "# mp.pyplot.figure(figsize=(15, 15))\n",
    "# index = 1\n",
    "\n",
    "# for parameter, param_range in dict.items(param_grid):\n",
    "#     cv_param = 'param_'+ parameter\n",
    "#     df_cv_results = pd.DataFrame(grid_search.cv_results_)[[ cv_param, 'mean_test_score']]\n",
    "#     df_cv_results = df_cv_results.sort_values(by = cv_param)\n",
    "#     mp.pyplot.subplot(3,2,index)\n",
    "#     mp.pyplot.title(cv_param)\n",
    "#     mp.pyplot.plot(df_cv_results[cv_param], df_cv_results['mean_test_score']) \n",
    "#     index += 1\n",
    "\n",
    "\n",
    "\n",
    "# for parameter, param_range in dict.items(param_grid):\n",
    "#     print(parameter, param_range)\n",
    "# df\n",
    "#     return \n",
    "    \n",
    "#     df = {}\n",
    "#     for i, score in enumerate(grid_search.grid_scores_):\n",
    "#         df[score[0][parameter]] = score[1]\n",
    "       \n",
    "    \n",
    "#     df = pd.DataFrame.from_dict(df, orient='index')\n",
    "#     df.reset_index(level=0, inplace=True)\n",
    "#     df = df.sort_values(by='index')\n",
    " \n",
    "#     mp.pyplot.subplot(3,2,index)\n",
    "#     plot = mp.pyplot.plot(df['index'], df[0])\n",
    "#     mp.pyplot.title(parameter)\n",
    "#     return plot, df\n",
    "\n",
    "\n",
    "\n",
    "# index = 1\n",
    "# mp.pyplot.figure(figsize=(16,12))\n",
    "# for parameter, param_range in dict.items(param_grid):\n",
    "#     parameter\n",
    "#     evaluate_param(parameter, param_range, index)\n",
    "#     index += 1\n",
    "\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# # n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # First create the base model to tune\n",
    "# rf = RandomForestClassifier()\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                       max_depth=50, max_features=1, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=1280,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n_estimators': 1280,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 1,\n",
    " 'max_depth': 50,\n",
    " 'bootstrap': False}\n",
    "rf_random.best_score_ \n",
    "0.9985050285403643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
